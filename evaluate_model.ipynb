{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:39:25.334574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 19:39:25.334714: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 19:39:25.344082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 19:39:25.380911: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 19:39:26.213351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 31.056 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 5.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import NuScenesDataSet\n",
    "from models import ultra_fast_bev, ultra_fast_bev_nmsbf\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "dataroot='../../../../datasets/nuscenes/'\n",
    "nuscd = NuScenesDataSet(dataroot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:40:04.382131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.522355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.522419: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.524696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.524742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.524776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.673797: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.673966: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.673977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-27 19:40:04.674125: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-27 19:40:04.674214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6019 5417 602\n",
      "377 339 38\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16 #to measure inference speed we need a big batch to take advantage of compute of the gpu\n",
    "train_camera_files_paths, val_camera_files_paths = nuscd.get_train_val_cameras_file_paths()\n",
    "\n",
    "file_path_lidar_train = '../../../../datasets/lidar_voxels_train/'\n",
    "file_path_lidar_val = '../../../../datasets/lidar_voxels_val/'\n",
    "train_lidar_files_paths, val_lidar_files_paths = nuscd.get_train_val_file_paths(file_path_lidar_train, file_path_lidar_val)\n",
    "\n",
    "file_path_bev_mask_train = '../../../../datasets/nusc_bev_mask_train/'\n",
    "file_path_bev_mask_val = '../../../../datasets/nusc_bev_mask_val/'\n",
    "train__bev_mask_files_paths, val__bev_mask_files_paths = nuscd.get_train_val_file_paths(file_path_bev_mask_train, file_path_bev_mask_val)\n",
    "\n",
    "# train_camera_files_paths = np.array(train_camera_files_paths)\n",
    "# train_lidar_files_paths = np.array(train_lidar_files_paths)[..., np.newaxis]\n",
    "# train__bev_mask_files_paths = np.array(train__bev_mask_files_paths)[..., np.newaxis]\n",
    "val_camera_files_paths = np.array(val_camera_files_paths)\n",
    "val_lidar_files_paths = np.array(val_lidar_files_paths)[..., np.newaxis]\n",
    "val__bev_mask_files_paths = np.array(val__bev_mask_files_paths)[..., np.newaxis]\n",
    "\n",
    "# train_files_paths = np.concatenate((train_camera_files_paths, train_lidar_files_paths, train__bev_mask_files_paths), axis=-1)\n",
    "val_files_paths = np.concatenate((val_camera_files_paths, val_lidar_files_paths, val__bev_mask_files_paths), axis=-1)\n",
    "\n",
    "val_index_day, val_index_night = nuscd.get_day_night_val_samples_indexes()\n",
    "val_files_paths_day = val_files_paths[val_index_day]\n",
    "val_files_paths_night = val_files_paths[val_index_night]\n",
    "\n",
    "def get_image(image_path):\n",
    "    image_shape = (448, 800)\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_shape)\n",
    "    return image\n",
    "\n",
    "def parse_samples(file_paths):\n",
    "    image0 = get_image(file_paths[0])\n",
    "    image1 = get_image(file_paths[1])\n",
    "    image2 = get_image(file_paths[2])\n",
    "    image3 = get_image(file_paths[3])\n",
    "    image4 = get_image(file_paths[4])\n",
    "    image5 = get_image(file_paths[5])\n",
    "\n",
    "    lidar = nuscd.read_binary_file(file_paths[6], dtype=tf.float32, shape=(200,200,4))\n",
    "    bev_mask = nuscd.read_binary_file(file_paths[7], dtype=tf.float32, shape=(200,200,3))\n",
    "    \n",
    "    return ((image0, image1, image2, image3, image4, image5, lidar), bev_mask)\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(train_files_paths)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_files_paths)\n",
    "val_dataset_day = tf.data.Dataset.from_tensor_slices(val_files_paths_day)\n",
    "val_dataset_night = tf.data.Dataset.from_tensor_slices(val_files_paths_night)\n",
    "\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=train_dataset.cardinality(), reshuffle_each_iteration=True).map(parse_samples, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# train_dataset = train_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "val_dataset = val_dataset.map(parse_samples, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset= val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "val_dataset_day = val_dataset_day.map(parse_samples, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset_day= val_dataset_day.batch(batch_size).prefetch(1)\n",
    "\n",
    "val_dataset_night = val_dataset_night.map(parse_samples, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset_night= val_dataset_night.batch(batch_size).prefetch(1)\n",
    "\n",
    "print(val_files_paths.shape[0], val_files_paths_day.shape[0], val_files_paths_night.shape[0])\n",
    "print(val_dataset.cardinality().numpy(), val_dataset_day.cardinality().numpy(), val_dataset_night.cardinality().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:40:35.511293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "tf.config.optimizer.set_jit(True) # Enable XLA\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "cameras_LUTs1 = nuscd.create_images_LUTs(image_size=(56,100))\n",
    "cameras_LUTs2 = nuscd.create_images_LUTs(image_size=(112,200))\n",
    "cameras_LUTs3 = nuscd.create_images_LUTs(image_size=(224,400))\n",
    "cameras_LUTs = [cameras_LUTs1, cameras_LUTs1, cameras_LUTs2, cameras_LUTs3] \n",
    "\n",
    "#Multy scale BEV features\n",
    "# model = ultra_fast_bev((448,800,3), cameras_LUTs, 3, 'EfficientNetB1',  'GroupNormalization', './model_weights/image_encoder_effnetb1_groupnorm_bs20_imagenet.h5')\n",
    "# model.load_weights('./model_weights/ufb_groupnorm_bs2.h5')\n",
    "\n",
    "# model = ultra_fast_bev((448,800,3), cameras_LUTs, 3, 'EfficientNetB1',  'BatchNormalization', './model_weights/image_encoder_effnetb1_batchnorm_bs20_imagenet.h5')\n",
    "# model.load_weights('./model_weights/ufb_batchnorm_bs2.h5')\n",
    "\n",
    "# model = ultra_fast_bev((448,800,3), cameras_LUTs, 3, 'EfficientNetB1',  'BatchNormalization', './model_weights/image_encoder_effnetb1_batchnorm_bs20_imagenet.h5', 'C')\n",
    "# model.load_weights('./model_weights/ufb_batchnorm_bs4_nl.h5')\n",
    "\n",
    "#No Multy scale BEV features\n",
    "# model = ultra_fast_bev_nmsbf((448,800,3), cameras_LUTs[0:1], 3, 'EfficientNetB1',  'GroupNormalization', './model_weights/image_encoder_effnetb1_groupnorm_bs20_imagenet.h5')\n",
    "# model.load_weights('./model_weights/ufb_groupnorm_bs2_nmsbf.h5')\n",
    "\n",
    "model = ultra_fast_bev_nmsbf((448,800,3), cameras_LUTs[0:1], 3, 'EfficientNetB1',  'BatchNormalization', './model_weights/image_encoder_effnetb1_batchnorm_bs20_imagenet.h5')\n",
    "# model.load_weights('./model_weights/ufb_batchnorm_bs2_nmsbf.h5')\n",
    "# model.load_weights('./model_weights/ufb_batchnorm_bs4_nmsbf.h5')\n",
    "# model.load_weights('./model_weights/ufb_batchnorm_bs6_nmsbf.h5')\n",
    "model.load_weights('./model_weights/ufb_batchnorm_bs5_nmsbf_run2.h5')\n",
    "\n",
    "# model = ultra_fast_bev_nmsbf((448,800,3), cameras_LUTs[0:1], 3, 'EfficientNetB1',  'BatchNormalization', './model_weights/image_encoder_effnetb1_batchnorm_bs20_imagenet.h5', 'C')\n",
    "# model.load_weights('./model_weights/ufb_batchnorm_bs4_nmsbf_nl.h5')\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.MeanIoU(num_classes=3, name = \"Mean_IOU\", sparse_y_true= False, sparse_y_pred=False),\n",
    "    tf.keras.metrics.IoU(num_classes=3, name = \"road\", target_class_ids = [0], sparse_y_true= False, sparse_y_pred=False),\n",
    "    tf.keras.metrics.IoU(num_classes=3, name = \"car\", target_class_ids = [1], sparse_y_true= False, sparse_y_pred=False),\n",
    "    tf.keras.metrics.IoU(num_classes=3, name = \"nothing\", target_class_ids = [2], sparse_y_true= False, sparse_y_pred=False)\n",
    "    ]\n",
    "\n",
    "model.compile(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importan! for some reason model.evaluate dosent evaluate right our model for the classes road and nothing when we use mixed_float16\n",
    "#if we split the data into day and night and calculate the weighted avarage mean_iou it should give as the iou of the hole dataset which it dosent\n",
    "#there seems to be a acumilation error that increases the biger the dataset is \n",
    "#if you want to evaluate using mixed presision use the method below, if you are going to use float32 use this method \n",
    "\n",
    "# model.evaluate(val_dataset)\n",
    "# model.evaluate(val_dataset_day) \n",
    "# model.evaluate(val_dataset_night) \n",
    "\n",
    "#Multy scale BEV features, wsl (ubuntu 22.04)\n",
    "#groupnorm_bs2 \n",
    "#inference time per sample: 41ms\n",
    "# Mean_IOU: 0.5760 - road: 0.6070 - car: 0.5051 - nothing: 0.6160 \n",
    "# Mean_IOU: 0.5872 - road: 0.6244 - car: 0.5041 - nothing: 0.6332 - day\n",
    "# Mean_IOU: 0.7537 - road: 0.7637 - car: 0.5397 - nothing: 0.9577 - night\n",
    "\n",
    "#batch_norm_bs2 \n",
    "#inference time per sample: 35ms\n",
    "# Mean_IOU: 0.5448 - road: 0.5688 - car: 0.4883 - nothing: 0.5774, \n",
    "# Mean_IOU: 0.5557 - road: 0.5856 - car: 0.4873 - nothing: 0.5941 - day\n",
    "# Mean_IOU: 0.7378 - road: 0.7369 - car: 0.5229 - nothing: 0.9536 - night \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metrics_reset():\n",
    "    metrics[0].reset_state()\n",
    "    metrics[1].reset_state()\n",
    "    metrics[2].reset_state()\n",
    "    metrics[3].reset_state()\n",
    "\n",
    "def iou_metrics_update(y, y_pred):\n",
    "    metrics[0].update_state(y, y_pred)\n",
    "    metrics[1].update_state(y, y_pred)\n",
    "    metrics[2].update_state(y, y_pred)\n",
    "    metrics[3].update_state(y, y_pred)\n",
    "\n",
    "def iou_metrics_results():\n",
    "    res1 = metrics[0].result().numpy()\n",
    "    res2 = metrics[1].result().numpy()\n",
    "    res3 = metrics[2].result().numpy()\n",
    "    res4 = metrics[3].result().numpy()\n",
    "\n",
    "    return np.array([res1, res2,res3, res4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference time in fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #wont compile with jit during inferece unless wraped in tf.function\n",
    "def tf_model(x):\n",
    "    return model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 13:01:07.199208: I external/local_xla/xla/service/service.cc:168] XLA service 0x95e66ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-17 13:01:07.199250: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-02-17 13:01:07.270473: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-17 13:01:07.890349: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-17 13:01:08.779569: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-17 13:01:28.616626: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f16[96,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[96,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-02-17 13:01:28.695380: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.078841439s\n",
      "Trying algorithm eng4{} for conv (f16[96,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[96,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-02-17 13:01:31.624210: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f16[96,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[96,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-02-17 13:01:32.374463: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.750340099s\n",
      "Trying algorithm eng4{} for conv (f16[96,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[96,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708167720.829693 1169521 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps = 69.95660136300408\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "idx = 0\n",
    "samples_n = 21\n",
    "for x, y in val_dataset.take(samples_n):\n",
    "    if idx==1: #start measuring from the second loop because model might compile in the fist loop\n",
    "        time_start = time.time()\n",
    "    y_pred = tf_model(x)\n",
    "    idx+=1\n",
    "time_end = time.time()\n",
    "time_per_sample = (time_end-time_start)/(batch_size*(samples_n-1))\n",
    "print(f'fps = {1/time_per_sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 13:05:39.816826: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f16[54,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[54,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-02-17 13:05:41.069057: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.252331693s\n",
      "Trying algorithm eng4{} for conv (f16[54,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[54,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-02-17 13:05:42.865572: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f16[54,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[54,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-02-17 13:05:44.155951: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.290468578s\n",
      "Trying algorithm eng4{} for conv (f16[54,112,200,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[54,225,401,96]{3,2,1,0}, f16[96,3,3,1]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76694775 0.82793605 0.5293352  0.9435721 ]\n",
      "[0.76714224 0.8315789  0.52917093 0.9406768 ]\n",
      "[0.75359184 0.7601371  0.53510743 0.96553123]\n"
     ]
    }
   ],
   "source": [
    "iou_metrics = np.array([0,0,0,0],dtype=np.float32)\n",
    "iou_metrics_day = np.array([0,0,0,0],dtype=np.float32)\n",
    "iou_metrics_night = np.array([0,0,0,0],dtype=np.float32)\n",
    "\n",
    "iou_metrics_reset()\n",
    "for x,y in val_dataset:\n",
    "    y_pred = tf_model(x)\n",
    "    iou_metrics_update(y, y_pred)\n",
    "iou_metrics = iou_metrics_results()\n",
    "\n",
    "iou_metrics_reset()\n",
    "for x,y in val_dataset_day:\n",
    "    y_pred = tf_model(x)\n",
    "    iou_metrics_update(y, y_pred)\n",
    "iou_metrics_day = iou_metrics_results()\n",
    "\n",
    "iou_metrics_reset()\n",
    "for x,y in val_dataset_night:\n",
    "    y_pred = tf_model(x)\n",
    "    iou_metrics_update(y, y_pred)\n",
    "iou_metrics_night = iou_metrics_results()\n",
    "\n",
    "\n",
    "print(iou_metrics)\n",
    "print(iou_metrics_day)\n",
    "print(iou_metrics_night)\n",
    "\n",
    "#Evaluation metrics \n",
    "#Mean_IOU, road_iou, car_iou, nothing_iou\n",
    "\n",
    "#Multy scale BEV features\n",
    "#group norm, batchsize=2\n",
    "#inference speed: 51.0 fps\n",
    "# [0.7592291  0.8294191 0.5050622 0.9432061]\n",
    "# [0.7591116  0.83296883 0.50410104 0.9402649 ] - day\n",
    "# [0.7562861  0.7637147  0.53965276 0.9654909 ] - night\n",
    "\n",
    "#batch norm, batchsize=2 \n",
    "#inference speed: 62.9 fps\n",
    "# [0.7412142  0.80142915 0.49831204 0.93390137]\n",
    "# [0.7407832  0.804848   0.4873187  0.93018293] - day\n",
    "# [0.7406412  0.7368739  0.5228709  0.96217865] - night\n",
    "\n",
    "#batch norm, batchsize=4, NO Lidar\n",
    "#inference speed: 62\n",
    "# [0.6381374  0.7344777  0.26831377 0.91162086]\n",
    "# [0.6387157  0.7402352  0.26864916 0.9072625 ]\n",
    "# [0.609385   0.62727    0.2560359  0.94484913]\n",
    "\n",
    "\n",
    "# No Multy scale BEV features\n",
    "#group norm, batchsize=2\n",
    "#inference speed: 57.4 fps\n",
    "# [0.7464096  0.80847263 0.49444437 0.93631184]\n",
    "# [0.7459523  0.8116656  0.4934519  0.93273926]\n",
    "# [0.7473073 0.7490108 0.5294082 0.963503]\n",
    "\n",
    "#batch norm, batchsize=2 \n",
    "#inference speed: 77.9\n",
    "# [0.75144154 0.80747795 0.5106551  0.9361916 ]\n",
    "# [0.7509284  0.81045216 0.5098626  0.9324705 ]\n",
    "# [0.75132614 0.75129515 0.5381671  0.96451616]\n",
    "\n",
    "#batch norm, batchsize=4\n",
    "#inference speed: 76.9 fps\n",
    "# [0.7517066  0.80723876 0.51169354 0.9361876 ]\n",
    "# [0.7512619  0.81029767 0.51095164 0.9325364 ]\n",
    "# [0.7504608  0.7498395  0.53755105 0.963992 ]\n",
    "\n",
    "#batch norm, batchsize=5 run2,  trained using weights from ufb_batchnorm_bs4_nmsbf\n",
    "#inference speed: 76.9 fps\n",
    "# [0.76694775 0.82793605 0.5293352  0.9435721 ]\n",
    "# [0.76714224 0.8315789  0.52917093 0.9406768 ]\n",
    "# [0.75359184 0.7601371  0.53510743 0.96553123]\n",
    "\n",
    "#batch norm, batchsize=4, NO Lidar\n",
    "#inference speed: 74 fps\n",
    "# [0.64134747 0.7353326  0.27623364 0.9124761 ]\n",
    "# [0.6418464 0.7407881 0.2767292 0.908022 ]\n",
    "# [0.6123806  0.6328632  0.25783348 0.94644517]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 601\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import cv2 \n",
    "import keyboard\n",
    "import os \n",
    "\n",
    "stop = 1\n",
    "key = ''\n",
    "sample = 0\n",
    "scale = 1/255.0\n",
    "y_pred_fig = None\n",
    "for x, y in val_dataset_night.unbatch().batch(1):\n",
    "    y_pred = model(x).numpy().reshape((200,200,3))\n",
    "    y_pred = tf.one_hot(np.argmax(y_pred, axis=-1),depth=3).numpy()\n",
    "    y_pred = nuscd.add_ego_vehicle_to_mask(y_pred, distance_around_ego=(100,100))\n",
    "    y_pred = nuscd.from_mask_to_rgb(y_pred)\n",
    "\n",
    "    y = nuscd.add_ego_vehicle_to_mask(y.numpy().reshape((200,200,3)), distance_around_ego=(100,100))\n",
    "    y = nuscd.from_mask_to_rgb(y)\n",
    "\n",
    "    lidar = (np.sum(x[6].numpy()[0, :, :, :], axis=-1)>=1)[..., np.newaxis]\n",
    "    lidar = np.concatenate((lidar,lidar,lidar),axis=-1)\n",
    "\n",
    "    # y =  np.clip(y + lidar *0.4, 0, 1)\n",
    "\n",
    "    top_img = tf.concat((x[1],x[0],x[2]), axis=2)\n",
    "    bottom_img = tf.concat((x[5],x[3],x[4]), axis=2)\n",
    "    img = tf.concat((top_img, bottom_img), axis=1)[0].numpy()*scale\n",
    "    \n",
    "    bev = np.concatenate((y, np.ones((y.shape[0],1,3), dtype=np.float32), y_pred), axis=1)\n",
    "    bev = cv2.resize(bev, (img.shape[1], int(bev.shape[0]*img.shape[1]/bev.shape[1]) ), cv2.INTER_LINEAR)\n",
    "\n",
    "    plot = np.concatenate((img, np.ones((6, img.shape[1],3)),bev), axis=0)\n",
    "\n",
    "    cv2.imshow('BEV',np.flip(plot, axis=-1))\n",
    "    \n",
    "    if key == ord('s') or stop ==1:\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        stop = 1\n",
    "\n",
    "    if key != ord('s') or stop==0:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        stop = 0\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    clear_output()\n",
    "    print(f'sample {sample}')\n",
    "    sample+=1\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 1/255.0\n",
    "# for x ,y in val_dataset_night.take(5):\n",
    "#     top_img = tf.concat((x[1],x[0],x[2]), axis=2)\n",
    "#     bottom_img = tf.concat((x[5],x[3],x[4]), axis=2)\n",
    "#     img = tf.concat((top_img, bottom_img), axis=1)[0].numpy()*scale\n",
    "#     lidar = x[6][0].numpy()\n",
    "#     bev_mask = y[0].numpy()\n",
    "#     bev_mask = nuscd.add_ego_vehicle_to_mask(bev_mask)\n",
    "#     bev_mask = nuscd.from_mask_to_rgb(bev_mask)\n",
    "\n",
    "#     plt.figure(figsize=(20,20))\n",
    "#     plt.subplot(2,2,(1,2))\n",
    "#     plt.axis(False)\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     plt.subplot(2,2,3)\n",
    "#     plt.axis(False)\n",
    "#     plt.imshow(bev_mask)\n",
    "\n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.axis(False)\n",
    "#     plt.imshow((np.sum(lidar, axis=-1)>=1)*1.0, cmap='gray')\n",
    "\n",
    "#     plt.subplots_adjust(wspace=0.0, hspace=0.0) \n",
    "#     plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condapy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
